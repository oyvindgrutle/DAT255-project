{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jens\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\Jens\\anaconda3\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "from IPython.display import Audio\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from fastai.vision.all import *\n",
    "from fastai.vision.widgets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress warnings that appear when uploading and classifying audio.\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo apt install ffmpeg\n",
    "# !pip install torchaudio ipywebrtc\n",
    "# !jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywebrtc import AudioRecorder, CameraStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The paths to where the recordings are being saved\n",
    "data_path = Path('../../data/')\n",
    "data_path.mkdir(exist_ok=True)\n",
    "audio_path = data_path/'audio'\n",
    "audio_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating the recorder to put in a widget later\n",
    "camera = CameraStream(constraints={'audio': True,'video':False})\n",
    "recorder = AudioRecorder(stream=camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../')\n",
    "model_path = path/'models'\n",
    "\n",
    "try:\n",
    "    learn_inf = load_learner(model_path/'model_V2.pkl')\n",
    "except:\n",
    "    posix_backup = pathlib.PosixPath\n",
    "    pathlib.PosixPath = pathlib.WindowsPath\n",
    "    learn_inf = load_learner(model_path/'model_V2.pkl')\n",
    "    pathlib.PosixPath = posix_backup\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_upload = widgets.FileUpload(accept=\".wav,.mp3\")\n",
    "out_rec = widgets.Output()\n",
    "out_pl = widgets.Output()\n",
    "lbl_pred = widgets.Label()\n",
    "lbl_pred.value = 'Please select audio'\n",
    "btn_run = widgets.Button(description='Classify recorded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_rec.clear_output()\n",
    "with out_rec: display(recorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_mel_spec_tfm(audio, dst_path = path/'../data/imgs/uploaded'):\n",
    "    data, sample_rate = audio\n",
    "    \n",
    "    n_fft = 1024\n",
    "    hop_length = 512\n",
    "    n_mels = 80\n",
    "    fmin = 20\n",
    "    fmax = sample_rate / 2 \n",
    "    \n",
    "    mel_spec_power = librosa.feature.melspectrogram(data, sr=sample_rate, n_fft=n_fft, \n",
    "                                                    hop_length=hop_length, \n",
    "                                                    n_mels=n_mels, power=2.0, \n",
    "                                                    fmin=fmin, fmax=fmax)\n",
    "    \n",
    "    #mel_spec_power = librosa.feature.melspectrogram(x, sr=sample_rate)\n",
    "    \n",
    "    mel_spec_db = librosa.power_to_db(mel_spec_power, ref=np.max)\n",
    "    \n",
    "    \n",
    "    dst_path.mkdir(exist_ok=True)\n",
    "    try:\n",
    "        fname = list(btn_upload.value)[0]\n",
    "    except:\n",
    "        fname = 'file.wav'\n",
    "    \n",
    "    plt.imsave(dst_path / (fname[:-4] + '.png'), mel_spec_db)\n",
    "    \n",
    "    return dst_path / (fname[:-4] + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_click(change):\n",
    "    out_pl.clear_output()\n",
    "    with out_pl: display(Audio(btn_upload.data[-1]))\n",
    "    dst_path = path/'../data/imgs/uploaded'\n",
    "    audio = librosa.load(io.BytesIO(btn_upload.data[-1]))\n",
    "    audio_img = log_mel_spec_tfm(audio, dst_path)\n",
    "    pred,pred_idx,probs = learn_inf.predict(audio_img)\n",
    "    lbl_pred.value = f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_click_live(change):\n",
    "    out_pl.clear_output()\n",
    "    update_live_audio()\n",
    "    audio = librosa.load(audio_path/'file.wav')\n",
    "    x, sr = audio\n",
    "    with out_pl: display(Audio(data=x, rate=sr))\n",
    "    dst_path = path/'../data/imgs/uploaded'\n",
    "    audio_img = log_mel_spec_tfm(audio, dst_path)\n",
    "    pred,pred_idx,probs = learn_inf.predict(audio_img)\n",
    "    lbl_pred.value = f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the audio file from the recorder as wav and puts it in a player\n",
    "def update_live_audio():\n",
    "    with open(audio_path/'recording.webm', 'wb') as f:\n",
    "        f.write(recorder.audio.value)\n",
    "    !ffmpeg -i ../../data/audio/recording.webm -ac 1 -f wav ../../data/audio/file.wav -y -hide_banner -loglevel panic\n",
    "    sig, sr = librosa.load(audio_path/'file.wav')\n",
    "    print(sig.shape)\n",
    "    Audio(data=sig, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_upload.observe(on_click, names=['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_run.on_click(on_click_live)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc86888541f84d9e9f8474dc19ebf35e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Select your audio by using \"upload\" or record by tapping the record button followeâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widgets.VBox([widgets.Label('Select your audio by using \"upload\" or record by tapping the record button followed by \"Classify recording\"'),\n",
    "      out_rec, btn_run, btn_upload, out_pl, lbl_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install voila\n",
    "#!jupyter serverextension enable voila --sys-prefix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
