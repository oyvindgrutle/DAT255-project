{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "792a5722",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62e9286",
   "metadata": {},
   "source": [
    "For this notebook we wanted to use the previously trained model that was trained on the dataset from the Freesound General-Purpose Audio Tagging Challenge, and use transfer learning on a smaller, simialr dataset. We chose to use the UrbanSound dataset that can be downloaded from here: https://urbansounddataset.weebly.com/urbansound.html.\n",
    "This dataset contains 1302 labeled sound recordings from 10 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ac4e0c",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b634ff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bc9f77",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf3df657",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = Path('../../data')\n",
    "URBAN_SOUND = DATA/'urban-sound'\n",
    "URBAN_SOUND_RECORDINGS = URBAN_SOUND/'data'\n",
    "#AUDIO_RECORDINGS = AUDIO_TAGGING/'audio_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7cfc00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_path = URBAN_SOUND/'train'\n",
    "dst_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "609da016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5) [Path('../../data/urban-sound/train'),Path('../../data/urban-sound/data'),Path('../../data/urban-sound/FREESOUNDCREDITS.txt'),Path('../../data/urban-sound/.DS_Store'),Path('../../data/urban-sound/UrbanSound_README.txt')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URBAN_SOUND.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02dc30bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) [Path('../../data/urban-sound/data/car_horn'),Path('../../data/urban-sound/data/jackhammer'),Path('../../data/urban-sound/data/siren'),Path('../../data/urban-sound/data/street_music'),Path('../../data/urban-sound/data/engine_idling'),Path('../../data/urban-sound/data/gun_shot'),Path('../../data/urban-sound/data/drilling'),Path('../../data/urban-sound/data/dog_bark'),Path('../../data/urban-sound/data/children_playing'),Path('../../data/urban-sound/data/air_conditioner')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URBAN_SOUND_RECORDINGS.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93a3cdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.utils import which\n",
    "\n",
    "AudioSegment.converter = which(\"ffmpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d457d8",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc5f5b4",
   "metadata": {},
   "source": [
    "The dataset contains recordings of very various length. Some are just shy of a second, some several minutes long. Therefore we need to do some data processing such that the model is given more similar data. We decided found that cutting the longer recordings to 20 seconds gave a much better result. We also had to get rid of some recordings that was of unsupported file formats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "966e222e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration before cut: 20.0\n",
      "Duration after cut: 10.0\n"
     ]
    }
   ],
   "source": [
    "children_playing = URBAN_SOUND_RECORDINGS/'street_music'\n",
    "children_playing.ls()\n",
    "sound = AudioSegment.from_file(children_playing/'7390.mp3')\n",
    "print(f'Duration before cut: {sound.duration_seconds}')\n",
    "s = sound[:10000]\n",
    "s.export(children_playing/'test.mp3', format='mp3')\n",
    "sound = AudioSegment.from_file(children_playing/'test.mp3')\n",
    "print(f'Duration after cut: {sound.duration_seconds}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c20f4fa",
   "metadata": {},
   "source": [
    "###### Converting the .mp3 files to .wav files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8bf9a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mp3_to_wav():\n",
    "    for subdir, dirs, files in os.walk(URBAN_SOUND_RECORDINGS): ## cin\n",
    "        for file in files:\n",
    "            #print os.path.join(subdir, file)\n",
    "            filepath = subdir + os.sep + file\n",
    "            source_path = Path(subdir)\n",
    "            #print(filepath)\n",
    "            #print(file)\n",
    "\n",
    "            if filepath.endswith('.mp3'):\n",
    "                sound = AudioSegment.from_file(filepath)\n",
    "                sound.export(filepath, 'wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40587187",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mp3_to_wav()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c85a2493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e345671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('WAV', 'PCM_16', 'FILE')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = sf.SoundFile(children_playing/'7390.mp3')\n",
    "f.format, f.subtype, f.endian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b017df06",
   "metadata": {},
   "source": [
    "###### Looping through each recording in the directory, removing files of unsupported file formats and cutting recordings over 20 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3270b353",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "numRemoved = 0\n",
    "for subdir, dirs, files in os.walk(URBAN_SOUND_RECORDINGS):\n",
    "    for file in files:\n",
    "        #print os.path.join(subdir, file)\n",
    "        filepath = subdir + os.sep + file\n",
    "        source_path = Path(subdir)\n",
    "        #print(filepath)\n",
    "        #print(file)\n",
    "\n",
    "        if not filepath.endswith(('.csv', '.json','.DS_Store','.aif','.flac')):\n",
    "            try:\n",
    "                f = sf.SoundFile(filepath)\n",
    "            except:\n",
    "                os.remove(filepath) # Remove files with unsupoorted format\n",
    "                numRemoved += 1\n",
    "                print(f'Removed files: {numRemoved}', end='/r')\n",
    "            else:\n",
    "                try:\n",
    "                    sound = AudioSegment.from_file(filepath)\n",
    "                    file_format = file.split(\".\")[-1]\n",
    "                    if sound.duration_seconds > 20:\n",
    "                        first_twenty = sound[:20000]\n",
    "                        first_twenty.export(filepath, format=file_format)\n",
    "                        count += 1\n",
    "                        print(f'Converted audio clips: {count}', end='\\r')\n",
    "                except:\n",
    "                    os.remove(filepath)\n",
    "                    numRemoved += 1\n",
    "                    print(f'Removed files: {numRemoved}', end='\\r')\n",
    "        else:\n",
    "            os.remove(filepath)\n",
    "            numRemoved += 1\n",
    "            print(f'Removed files: {numRemoved}', end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "619cfe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_mel_spec_tfm(fname, label, src_path , dst_path):\n",
    "    data, sample_rate = librosa.load(src_path/fname)\n",
    "    \n",
    "    n_fft = 1024\n",
    "    hop_length = 512\n",
    "    n_mels = 80\n",
    "    fmin = 20\n",
    "    fmax = sample_rate / 2 \n",
    "    \n",
    "    mel_spec_power = librosa.feature.melspectrogram(data, sr=sample_rate, n_fft=n_fft, \n",
    "                                                    hop_length=hop_length, \n",
    "                                                    n_mels=n_mels, power=2.0, \n",
    "                                                    fmin=fmin, fmax=fmax)\n",
    "    \n",
    "    #mel_spec_power = librosa.feature.melspectrogram(x, sr=sample_rate)\n",
    "    \n",
    "    mel_spec_db = librosa.power_to_db(mel_spec_power, ref=np.max)\n",
    "        \n",
    "    dst_path = dst_path / label\n",
    "    dst_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    dst_fname = dst_path / (fname[:-4] + '.png')\n",
    "    #print(dst_fname)\n",
    "    plt.imsave(dst_fname, mel_spec_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34f81631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566f31f5",
   "metadata": {},
   "source": [
    "## Converting the recordings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249c076e",
   "metadata": {},
   "source": [
    "As with the previous notebooks, we want to represent the recordings as images to be used in a CNN. Therefore we do as earlier and convert the recordings to mel spectograms. The images will be saved in folders where the folder name is the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fcb8c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_spec():\n",
    "    count = 0\n",
    "    for subdir, dirs, files in os.walk(URBAN_SOUND_RECORDINGS):\n",
    "        for file in files:\n",
    "            #print os.path.join(subdir, file)\n",
    "            filepath = subdir + os.sep + file\n",
    "            source_path = Path(subdir)\n",
    "            #print(filepath)\n",
    "            #print(file)\n",
    "            count += 1\n",
    "            if count % 10 == 0:\n",
    "                print(count, end='\\r')\n",
    "            label = subdir.split(\"/\")[-1]\n",
    "            #print(label)\n",
    "            log_mel_spec_tfm(file, label, source_path, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a67c62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convertto_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "133c0a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('../../data/urban-sound/train')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dst_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24604ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m../../data/urban-sound/train\u001b[00m\r\n",
      "├── \u001b[01;34mair_conditioner\u001b[00m\r\n",
      "├── \u001b[01;34mcar_horn\u001b[00m\r\n",
      "├── \u001b[01;34mchildren_playing\u001b[00m\r\n",
      "├── \u001b[01;34mdog_bark\u001b[00m\r\n",
      "├── \u001b[01;34mdrilling\u001b[00m\r\n",
      "├── \u001b[01;34mengine_idling\u001b[00m\r\n",
      "├── \u001b[01;34mgun_shot\u001b[00m\r\n",
      "├── \u001b[01;34mjackhammer\u001b[00m\r\n",
      "├── \u001b[01;34msiren\u001b[00m\r\n",
      "└── \u001b[01;34mstreet_music\u001b[00m\r\n",
      "\r\n",
      "10 directories, 0 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree -L 1 $dst_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78519f36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfx",
   "language": "python",
   "name": "tfx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
