{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from IPython.display import Audio\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from fastai.vision.all import *\n",
    "from fastai.vision.widgets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../')\n",
    "model_path = path/'models'\n",
    "\n",
    "try:\n",
    "    learn_inf = load_learner(model_path/'sound_model_V1')\n",
    "except:\n",
    "    posix_backup = pathlib.PosixPath\n",
    "    pathlib.PosixPath = pathlib.WindowsPath\n",
    "    learn_inf = load_learner(model_path/'sound_model_V1')\n",
    "    pathlib.PosixPath = posix_backup\n",
    "    \n",
    "btn_upload = widgets.FileUpload(accept=\".wav,.mp3\")\n",
    "out_pl = widgets.Output()\n",
    "lbl_pred = widgets.Label()\n",
    "lbl_pred.value = 'Please select audio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_mel_spec_tfm(audio_upload, dst_path = path/'../data/imgs/uploaded'):\n",
    "    data, sample_rate = librosa.load(io.BytesIO(audio_upload.data[-1]))\n",
    "    \n",
    "    n_fft = 1024\n",
    "    hop_length = 512\n",
    "    n_mels = 80\n",
    "    fmin = 20\n",
    "    fmax = sample_rate / 2 \n",
    "    \n",
    "    mel_spec_power = librosa.feature.melspectrogram(data, sr=sample_rate, n_fft=n_fft, \n",
    "                                                    hop_length=hop_length, \n",
    "                                                    n_mels=n_mels, power=2.0, \n",
    "                                                    fmin=fmin, fmax=fmax)\n",
    "    \n",
    "    #mel_spec_power = librosa.feature.melspectrogram(x, sr=sample_rate)\n",
    "    \n",
    "    mel_spec_db = librosa.power_to_db(mel_spec_power, ref=np.max)\n",
    "    \n",
    "    \n",
    "    dst_path.mkdir(exist_ok=True)\n",
    "    fname = list(audio_upload.value)[0]\n",
    "    \n",
    "    plt.imsave(dst_path / (fname[:-4] + '.png'), mel_spec_db)\n",
    "    \n",
    "    return dst_path / (fname[:-4] + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_click_classify(change):\n",
    "    out_pl.clear_output()\n",
    "    with out_pl: display(Audio(btn_upload.data[-1]))\n",
    "    dst_path = path/'../data/imgs/uploaded'\n",
    "    audio_img = log_mel_spec_tfm(btn_upload, dst_path)\n",
    "    pred,pred_idx,probs = learn_inf.predict(audio_img)\n",
    "    lbl_pred.value = f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_upload.observe(on_click_classify, names=['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2196e49c29484c8b1383b6d2c603cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Select your audio'), FileUpload(value={}, accept='.wav,.mp3', description='Upload'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-b4d504f916d7>:10: FutureWarning: Pass y=[-5.1559568e-06 -1.4841992e-06  9.4970856e-06 ... -9.5554744e-04\n",
      " -8.0968329e-04 -6.3658389e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_spec_power = librosa.feature.melspectrogram(data, sr=sample_rate, n_fft=n_fft,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widgets.VBox([widgets.Label('Select your audio'),\n",
    "      btn_upload, out_pl, lbl_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install voila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!jupyter serverextension enable voila --sys-prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
